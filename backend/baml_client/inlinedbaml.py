# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\n// Using the new OpenAI Responses API for enhanced formatting\n\n// Example Vertex AI client (uncomment to use)\nclient<llm> Gemini {\n  provider google-ai\n  options {\n    model \"gemini-2.0-flash-lite\"\n    api_key env.GEMINI_API_KEY\n  }\n}\n\n\n",
    "ecommerce.baml": "enum ConversationType {\n  GENERAL_CONVERSATION\n  PRODUCT_RECOMMENDATION  \n  IMAGE_SEARCH\n}\n\nclass ProductRecommendation {\n  product_id string\n  title string\n  description string\n  category string\n  price float?\n  rating float?\n  relevance_score float\n  reason string\n}\n\nclass SearchFilters {\n  category string?\n  min_price float?\n  max_price float?\n  min_rating float?\n}\n\n// ADD THESE NEW FUNCTIONS to your existing ecommerce.baml:\n\nfunction ClassifyUserIntent(user_message: string, has_image: bool) -> ConversationType {\n  client Gemini\n  prompt #\"\n    Classify this user message into one of these categories:\n    \n    User message: \"{{user_message}}\"\n    Has image attached: {{has_image}}\n    \n    Categories:\n    - GENERAL_CONVERSATION: Greetings, questions about the agent capabilities, general chat\n    - PRODUCT_RECOMMENDATION: Requests for product suggestions or search based on text\n    - IMAGE_SEARCH: User wants to find products based on an uploaded image\n    \n    If has_image is true, return IMAGE_SEARCH.\n    \n    Return only the category name.\n  \"#\n}\n\nfunction HandleGeneralConversation(user_message: string) -> string {\n  client Gemini\n  prompt #\"\n    You are Cartly, a helpful AI shopping assistant for an e-commerce website.\n    \n    User message: \"{{user_message}}\"\n    \n    Respond in a friendly, helpful way. If asked about your capabilities, mention:\n    - I can help you find products by describing what you need\n    - I can search for products based on images you upload\n    - I can have general conversations about shopping and products\n    - I have access to 800 curated products from top e-commerce categories\n    \n    If asked about your name, say you're Cartly, the AI shopping assistant.\n    Keep responses concise and engaging.\n  \"#\n}\n\nfunction AnalyzeProductImage(image_description: string) -> string {\n  client Gemini\n  prompt #\"\n    Based on this image description: \"{{image_description}}\"\n    \n    Generate a search query to find similar or related products in an e-commerce catalog.\n    Focus on:\n    - Product type and category\n    - Key visual features (color, style, material)\n    - Likely use case or purpose\n    - Brand or style characteristics\n    \n    Return a concise search query that would find similar products.\n  \"#\n}\n\n\nfunction AnalyzeSearchIntent(query: string) -> string {\n  client Gemini\n  prompt #\"\n    Analyze the following search query and extract the user's intent:\n    Query: \"{{query}}\"\n    \n    Determine:\n    1. What type of product they're looking for\n    2. Any implicit filters (price range, quality, etc.)\n    3. The main search keywords to use\n    \n    Return a refined search query that captures the user's intent clearly.\n    Keep it concise and focused on the main product attributes.\n  \"#\n}\n\nfunction GenerateProductRecommendations(\n  query: string, \n  similar_products: string,\n  user_filters: string?\n) -> ProductRecommendation[] {\n  client Gemini\n  prompt #\"\n    Based on the user query: \"{{query}}\"\n    \n    Here are similar products found:\n    {{similar_products}}\n    \n    {% if user_filters %}\n    User preferences: {{user_filters}}\n    {% endif %}\n    \n    Analyze these products and return the top 5 most relevant recommendations.\n    For each product, provide:\n    - A relevance_score (0-100)\n    - A clear reason why this product matches the user's needs\n    \n    Focus on products that best match the user's intent, considering:\n    - Product quality (rating)\n    - Value for money\n    - Feature alignment with user needs\n    - Category relevance\n    \n    Return as JSON array.\n  \"#\n}\n\nfunction ExplainRecommendation(\n  product: string,\n  user_query: string\n) -> string {\n  client Gemini\n  prompt #\"\n    Explain why this product is a good match for the user's search:\n    \n    User Query: \"{{user_query}}\"\n    Product: {{product}}\n    \n    Provide a personalized explanation that highlights:\n    1. How this product meets their specific needs\n    2. Key features that make it stand out\n    3. Value proposition\n    \n    Keep the explanation conversational and helpful, like a knowledgeable sales assistant.\n  \"#\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.209.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
}

def get_baml_files():
    return _file_map