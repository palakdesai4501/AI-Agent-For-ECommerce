# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\n// Using the new OpenAI Responses API for enhanced formatting\n\n// Example Vertex AI client (uncomment to use)\nclient<llm> Gemini {\n  provider google-ai\n  options {\n    model \"gemini-2.5-flash-lite\"\n    api_key env.GEMINI_API_KEY\n  }\n}\n\n\n",
    "ecommerce.baml": "enum ConversationType {\n  GENERAL_CONVERSATION\n  PRODUCT_RECOMMENDATION  \n  IMAGE_SEARCH\n}\n\nclass ProductRecommendation {\n  product_id string\n  title string\n  description string\n  category string\n  price float?\n  rating float?\n  relevance_score float\n  reason string\n}\n\nclass SearchFilters {\n  category string?\n  min_price float?\n  max_price float?\n  min_rating float?\n}\n\n// Unified single-entrypoint helper types\nclass UserQueryInput {\n  user_message string\n  has_image bool\n  image_description string?\n}\n\nclass AgentDirective {\n  intent ConversationType\n  // For GENERAL_CONVERSATION\n  reply string?\n  // For PRODUCT_RECOMMENDATION or IMAGE_SEARCH\n  refined_query string?\n  user_filters string?\n}\n\nfunction HandleGeneralConversation(user_message: string) -> string {\n  client Gemini\n  prompt #\"\n    You are Cartly, a helpful AI shopping assistant for an e-commerce website.\n    \n    User message: \"{{user_message}}\"\n    \n    Respond in a friendly, helpful way. If asked about your capabilities, mention:\n    - I can help you find products by describing what you need\n    - I can search for products based on images you upload\n    - I can have general conversations about shopping and products\n    - I have access to 800 curated products from top e-commerce categories\n    \n    If asked about your name, say you're Cartly, the AI shopping assistant.\n    Keep responses concise and engaging.\n  \"#\n}\n\nfunction AnalyzeProductImage(image_description: string) -> string {\n  client Gemini\n  prompt #\"\n    You are an e-commerce search expert. Convert this structured product description into a focused search query.\n\n    Description:\n    {{image_description}}\n\n    TASK: Create a SHORT search query (5-10 words max) that captures the most important searchable attributes.\n\n    RULES:\n    1. Start with the product type (most important)\n    2. Add 2-3 key distinguishing features (color, material, style, target audience)\n    3. Use simple, common e-commerce terms\n    4. Avoid long descriptions or sentences\n    5. Focus on what would match in a product catalog\n\n    EXAMPLES:\n    Input: \"Product Type: Headphones, Colors: black, Features: wireless, over-ear, Target: adults\"\n    Output: \"wireless headphones black over-ear bluetooth\"\n\n    Input: \"Product Type: Jacket, Category: clothing, Colors: gray navy, Target: kids boys\"\n    Output: \"boys jacket gray navy kids clothing\"\n\n    Input: \"Product Type: Water bottle, Features: insulated, stainless steel, Colors: blue\"\n    Output: \"insulated water bottle stainless steel blue\"\n\n    Now generate the search query:\n  \"#\n}\n\n\n// (Removed unused AnalyzeSearchIntent)\n\n// Single entrypoint: take one input and decide what to do.\nfunction HandleUserQuery(input: UserQueryInput) -> AgentDirective {\n  client Gemini\n  prompt #\"\n    {{ ctx.output_format }}\n\n    You are Cartly, an AI shopping assistant. Decide the user's intent and provide\n    either a direct reply (for GENERAL_CONVERSATION) or a refined_query (for\n    PRODUCT_RECOMMENDATION or IMAGE_SEARCH). Use the following rules:\n\n    - If input.has_image is true, set intent = IMAGE_SEARCH. Use input.image_description\n      to craft a concise refined_query for catalog search.\n    - Otherwise, classify input.user_message as one of:\n        GENERAL_CONVERSATION | PRODUCT_RECOMMENDATION\n    - For GENERAL_CONVERSATION: set reply to a concise, helpful answer. Do not\n      request tools.\n    - For PRODUCT_RECOMMENDATION: create a refined_query that captures product type,\n      key attributes, and any implicit constraints. Keep it short.\n\n    STRICT AVAILABILITY / NO FABRICATION POLICY:\n    - Never invent or imply availability of items that are not in the catalog.\n    - Preserve hard constraints in the refined_query (e.g., color, brand, model, size, material).\n    - Do not relax hard constraints unless the user explicitly permits alternatives.\n    - If the query is \"Recommend me red tshirt\" and the catalog has no red t-shirts,\n      keep the refined_query strict (e.g., \"red t-shirt\") so downstream search can return no results.\n      The system should then clearly say no matching products were found rather than suggesting other colors.\n    - When unsure between multiple interpretations, prefer the one that does not over-claim availability.\n\n    Input:\n    message: \"{{ input.user_message }}\"\n    has_image: {{ input.has_image }}\n    image_description: {{ input.image_description }}\n\n  \"#\n}\n\n// (Removed unused ToolSearchByText â€” handled by Python SearchEngine)\n\n// TOOL 2: Context-aware product recommendations (RAG)\nfunction GenerateProductRecommendations(\n  user_query: string,\n  retrieved_products: string\n) -> string {\n  client Gemini\n  prompt #\"\n    {{ ctx.output_format }}\n\n    You are Cartly, an AI shopping assistant. You have retrieved products from the catalog based on the user's query.\n    Your task is to generate a BRIEF, clean response about the products.\n\n    CRITICAL RULES:\n    1. Keep response SHORT - 1-2 sentences maximum\n    2. Count the ACTUAL number of products in the retrieved list\n    3. If found: \"I found [exact_count] product(s) for you.\" (use singular \"product\" if count is 1)\n    4. If not found or empty list: \"I couldn't find products matching your request.\"\n    5. DO NOT list product details, features, prices, or descriptions in text\n    6. DO NOT explain why products match or don't match\n    7. The products will be displayed visually with images below your message\n    8. Never fabricate details or counts\n\n    User Query: \"{{user_query}}\"\n\n    Retrieved Products:\n    {{retrieved_products}}\n\n    Generate a MINIMAL response (1-2 sentences only) with the EXACT product count:\n  \"#\n}\n\n// TOOL 3: Single product explanation helper\nfunction ExplainRecommendation(\n  product: string,\n  user_query: string\n) -> string {\n  client Gemini\n  prompt #\"\n    Explain why this product is a good match for the user's search.\n    USE ONLY the information present in Product. Do not assume brand, color,\n    availability, or features that are not explicitly provided.\n    If the product does not clearly satisfy key constraints in the User Query\n    (e.g., color, size, model), state that directly and avoid claiming it does.\n\n    User Query: \"{{user_query}}\"\n    Product: {{product}}\n\n    Provide a personalized explanation that highlights:\n    1. How this product meets their specific needs\n    2. Key features that make it stand out\n    3. Value proposition\n\n    Keep the explanation conversational and helpful, like a knowledgeable sales assistant.\n    Be precise and do not fabricate details beyond the provided Product fields.\n  \"#\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.209.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
}

def get_baml_files():
    return _file_map