# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\n// Using the new OpenAI Responses API for enhanced formatting\n\n// Example Vertex AI client (uncomment to use)\nclient<llm> Gemini {\n  provider google-ai\n  options {\n    model \"gemini-2.5-flash-lite\"\n    api_key env.GEMINI_API_KEY\n  }\n}\n\n\n",
    "ecommerce.baml": "enum ConversationType {\n  GENERAL_CONVERSATION\n  PRODUCT_RECOMMENDATION  \n  IMAGE_SEARCH\n}\n\nclass ProductRecommendation {\n  product_id string\n  title string\n  description string\n  category string\n  price float?\n  rating float?\n  relevance_score float\n  reason string\n}\n\nclass SearchFilters {\n  category string?\n  min_price float?\n  max_price float?\n  min_rating float?\n}\n\n// Unified single-entrypoint helper types\nclass UserQueryInput {\n  user_message string\n  has_image bool\n  image_description string?\n}\n\nclass AgentDirective {\n  intent ConversationType\n  // For GENERAL_CONVERSATION\n  reply string?\n  // For PRODUCT_RECOMMENDATION or IMAGE_SEARCH\n  refined_query string?\n  user_filters string?\n}\n\nfunction HandleGeneralConversation(user_message: string) -> string {\n  client Gemini\n  prompt #\"\n    You are Cartly, a helpful AI shopping assistant for an e-commerce website.\n    \n    User message: \"{{user_message}}\"\n    \n    Respond in a friendly, helpful way. If asked about your capabilities, mention:\n    - I can help you find products by describing what you need\n    - I can search for products based on images you upload\n    - I can have general conversations about shopping and products\n    - I have access to 800 curated products from top e-commerce categories\n    \n    If asked about your name, say you're Cartly, the AI shopping assistant.\n    Keep responses concise and engaging.\n  \"#\n}\n\nfunction AnalyzeProductImage(image_description: string) -> string {\n  client Gemini\n  prompt #\"\n    Based on this image description: \"{{image_description}}\"\n    \n    Generate a search query to find similar or related products in an e-commerce catalog.\n    Focus on:\n    - Product type and category\n    - Key visual features (color, style, material)\n    - Likely use case or purpose\n    - Brand or style characteristics\n    \n    Return a concise search query that would find similar products.\n  \"#\n}\n\n\n// (Removed unused AnalyzeSearchIntent)\n\n// Single entrypoint: take one input and decide what to do.\nfunction HandleUserQuery(input: UserQueryInput) -> AgentDirective {\n  client Gemini\n  prompt #\"\n    {{ ctx.output_format }}\n\n    You are Cartly, an AI shopping assistant. Decide the user's intent and provide\n    either a direct reply (for GENERAL_CONVERSATION) or a refined_query (for\n    PRODUCT_RECOMMENDATION or IMAGE_SEARCH). Use the following rules:\n\n    - If input.has_image is true, set intent = IMAGE_SEARCH. Use input.image_description\n      to craft a concise refined_query for catalog search.\n    - Otherwise, classify input.user_message as one of:\n        GENERAL_CONVERSATION | PRODUCT_RECOMMENDATION\n    - For GENERAL_CONVERSATION: set reply to a concise, helpful answer. Do not\n      request tools.\n    - For PRODUCT_RECOMMENDATION: create a refined_query that captures product type,\n      key attributes, and any implicit constraints. Keep it short.\n\n    STRICT AVAILABILITY / NO FABRICATION POLICY:\n    - Never invent or imply availability of items that are not in the catalog.\n    - Preserve hard constraints in the refined_query (e.g., color, brand, model, size, material).\n    - Do not relax hard constraints unless the user explicitly permits alternatives.\n    - If the query is \"Recommend me red tshirt\" and the catalog has no red t-shirts,\n      keep the refined_query strict (e.g., \"red t-shirt\") so downstream search can return no results.\n      The system should then clearly say no matching products were found rather than suggesting other colors.\n    - When unsure between multiple interpretations, prefer the one that does not over-claim availability.\n\n    Input:\n    message: \"{{ input.user_message }}\"\n    has_image: {{ input.has_image }}\n    image_description: {{ input.image_description }}\n\n  \"#\n}\n\n// (Removed unused ToolSearchByText â€” handled by Python SearchEngine)\n\n// TOOL 2: Context-aware product recommendations (RAG)\nfunction GenerateProductRecommendations(\n  user_query: string,\n  retrieved_products: string\n) -> string {\n  client Gemini\n  prompt #\"\n    {{ ctx.output_format }}\n\n    You are Cartly, an AI shopping assistant. You have retrieved products from the catalog based on the user's query.\n    Your task is to generate a BRIEF, clean response about the products.\n\n    CRITICAL RULES:\n    1. Keep response SHORT - 1-2 sentences maximum\n    2. Just say if products were found or not\n    3. If found: \"I found [number] products for you.\"\n    4. If not found: \"I couldn't find products matching your request.\"\n    5. DO NOT list product details, features, prices, or descriptions in text\n    6. DO NOT explain why products match or don't match\n    7. The products will be displayed visually with images below your message\n    8. Never fabricate details\n\n    User Query: \"{{user_query}}\"\n\n    Retrieved Products:\n    {{retrieved_products}}\n\n    Generate a MINIMAL response (1-2 sentences only):\n  \"#\n}\n\n// TOOL 3: Single product explanation helper\nfunction ExplainRecommendation(\n  product: string,\n  user_query: string\n) -> string {\n  client Gemini\n  prompt #\"\n    Explain why this product is a good match for the user's search.\n    USE ONLY the information present in Product. Do not assume brand, color,\n    availability, or features that are not explicitly provided.\n    If the product does not clearly satisfy key constraints in the User Query\n    (e.g., color, size, model), state that directly and avoid claiming it does.\n\n    User Query: \"{{user_query}}\"\n    Product: {{product}}\n\n    Provide a personalized explanation that highlights:\n    1. How this product meets their specific needs\n    2. Key features that make it stand out\n    3. Value proposition\n\n    Keep the explanation conversational and helpful, like a knowledgeable sales assistant.\n    Be precise and do not fabricate details beyond the provided Product fields.\n  \"#\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.209.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
}

def get_baml_files():
    return _file_map